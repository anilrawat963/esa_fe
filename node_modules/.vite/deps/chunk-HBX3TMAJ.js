import {
  r as r2
} from "./chunk-7YJLACUB.js";
import {
  o
} from "./chunk-HETHJJO6.js";
import {
  n as n2
} from "./chunk-CHC4AAHW.js";
import {
  d as d2
} from "./chunk-NDWECAKM.js";
import {
  u
} from "./chunk-KTMKDXZP.js";
import {
  i
} from "./chunk-CT7HOWYG.js";
import {
  e as e2
} from "./chunk-BZBDEPRV.js";
import {
  p
} from "./chunk-MXP2VO3L.js";
import {
  d,
  f
} from "./chunk-OWSUTT7E.js";
import {
  e
} from "./chunk-COMSADUT.js";
import {
  r
} from "./chunk-EGPAQBOO.js";
import {
  s
} from "./chunk-WJ3E33GQ.js";
import {
  n,
  t
} from "./chunk-CFXCM2NO.js";

// node_modules/@arcgis/core/chunks/Pattern.glsl.js
var u2 = 0.70710678118;
var f2 = u2;
var w = 0.08715574274;
var b = 10;
var h = 1;
function y(y2) {
  const x2 = new s(), { vertex: j, fragment: C, attributes: V, varyings: R } = x2, P = 9 === y2.output;
  f(j, y2), x2.include(o), x2.include(r2, y2), x2.include(u, y2), x2.include(d2, y2), x2.fragment.include(p, y2), x2.include(n2, y2), x2.include(i, y2), y2.draped ? j.uniforms.add(new r("worldToScreenRatio", (e3) => 1 / e3.screenToPCSRatio)) : V.add("boundingRect", "mat3"), V.add("position", "vec3"), V.add("uvMapSpace", "vec4"), y2.hasVVColor && V.add("colorFeatureAttribute", "float"), y2.hasVertexColors || R.add("vColor", "vec4"), R.add("vpos", "vec3", { invariant: true }), R.add("vuv", "vec2"), j.uniforms.add(new e("uColor", (e3) => e3.color));
  const T = 3 === y2.style || 4 === y2.style || 5 === y2.style;
  return T && j.code.add(t`
      const mat2 rotate45 = mat2(${t.float(u2)}, ${t.float(-f2)},
                                 ${t.float(f2)}, ${t.float(u2)});
    `), y2.draped || (d(j, y2), j.uniforms.add(new r("worldToScreenPerDistanceRatio", (e3) => 1 / e3.camera.perScreenPixelRatio)), j.code.add(t`vec3 projectPointToLineSegment(vec3 center, vec3 halfVector, vec3 point) {
float projectedLength = dot(halfVector, point - center) / dot(halfVector, halfVector);
return center + halfVector * clamp(projectedLength, -1.0, 1.0);
}`), j.code.add(t`vec3 intersectRayPlane(vec3 rayDir, vec3 rayOrigin, vec3 planeNormal, vec3 planePoint) {
float d = dot(planeNormal, planePoint);
float t = (d - dot(planeNormal, rayOrigin)) / dot(planeNormal, rayDir);
return rayOrigin + t * rayDir;
}`), j.code.add(t`
      float boundingRectDistanceToCamera() {
        vec3 center = vec3(boundingRect[0][0], boundingRect[0][1], boundingRect[0][2]);
        vec3 halfU = vec3(boundingRect[1][0], boundingRect[1][1], boundingRect[1][2]);
        vec3 halfV = vec3(boundingRect[2][0], boundingRect[2][1], boundingRect[2][2]);
        vec3 n = normalize(cross(halfU, halfV));

        vec3 viewDir = - vec3(view[0][2], view[1][2], view[2][2]);

        float viewAngle = dot(viewDir, n);
        float minViewAngle = ${t.float(w)};

        if (abs(viewAngle) < minViewAngle) {
          // view direction is (almost) parallel to plane -> clamp it to min angle
          float normalComponent = sign(viewAngle) * minViewAngle - viewAngle;
          viewDir = normalize(viewDir + normalComponent * n);
        }

        // intersect view direction with infinite plane that contains bounding rect
        vec3 planeProjected = intersectRayPlane(viewDir, cameraPosition, n, center);

        // clip to bounds by projecting to u and v line segments individually
        vec3 uProjected = projectPointToLineSegment(center, halfU, planeProjected);
        vec3 vProjected = projectPointToLineSegment(center, halfV, planeProjected);

        // use to calculate the closest point to camera on bounding rect
        vec3 closestPoint = uProjected + vProjected - center;

        return length(closestPoint - cameraPosition);
      }
    `)), j.code.add(t`
    vec2 scaledUV() {
      vec2 uv = uvMapSpace.xy ${n(T, " * rotate45")};
      vec2 uvCellOrigin = uvMapSpace.zw ${n(T, " * rotate45")};

      ${n(!y2.draped, t`float distanceToCamera = boundingRectDistanceToCamera();
               float worldToScreenRatio = worldToScreenPerDistanceRatio / distanceToCamera;`)}

      // Logarithmically discretize ratio to avoid jittering
      float step = 0.1;
      float discreteWorldToScreenRatio = log(worldToScreenRatio);
      discreteWorldToScreenRatio = ceil(discreteWorldToScreenRatio / step) * step;
      discreteWorldToScreenRatio = exp(discreteWorldToScreenRatio);

      vec2 uvOffset = mod(uvCellOrigin * discreteWorldToScreenRatio, ${t.float(b)});
      return uvOffset + (uv * discreteWorldToScreenRatio);
    }
  `), j.main.add(t`
    vuv = scaledUV();
    vpos = position;
    forwardViewPosDepth((view * vec4(vpos, 1.0)).xyz);
    forwardNormalizedVertexColor();
    forwardObjectAndLayerIdColor();
    ${y2.hasVertexColors ? "vColor *= uColor;" : y2.hasVVColor ? "vColor = uColor * interpolateVVColor(colorFeatureAttribute);" : "vColor = uColor;"}
    gl_Position = transformPosition(proj, view, vpos);
  `), C.include(e2), y2.draped && C.uniforms.add(new r("texelSize", (e3) => 1 / e3.camera.pixelRatio)), P || (C.code.add(t`
      const float lineWidth = ${t.float(h)};
      const float spacing = ${t.float(b)};
      const float spacingINV = ${t.float(1 / b)};

      float coverage(float p, float txlSize) {
        p = mod(p, spacing);

        float halfTxlSize = txlSize / 2.0;

        float start = p - halfTxlSize;
        float end = p + halfTxlSize;

        float coverage = (ceil(end * spacingINV) - floor(start * spacingINV)) * lineWidth;
        coverage -= min(lineWidth, mod(start, spacing));
        coverage -= max(lineWidth - mod(end, spacing), 0.0);

        return coverage / txlSize;
      }
    `), y2.draped || C.code.add(t`const int maxSamples = 5;
float sampleAA(float p) {
vec2 dxdy = abs(vec2(dFdx(p), dFdy(p)));
float fwidth = dxdy.x + dxdy.y;
ivec2 samples = 1 + ivec2(clamp(dxdy, 0.0, float(maxSamples - 1)));
vec2 invSamples = 1.0 / vec2(samples);
float accumulator = 0.0;
for (int j = 0; j < maxSamples; j++) {
if(j >= samples.y) {
break;
}
for (int i = 0; i < maxSamples; i++) {
if(i >= samples.x) {
break;
}
vec2 step = vec2(i,j) * invSamples - 0.5;
accumulator += coverage(p + step.x * dxdy.x + step.y * dxdy.y, fwidth);
}
}
accumulator /= float(samples.x * samples.y);
return accumulator;
}`)), C.main.add(t`
    discardBySlice(vpos);
    discardByTerrainDepth();
    vec4 color = vColor;
    ${n(!P, t`color.a *= ${S(y2)};`)}
    outputColorHighlightOID(color, vpos, color.rgb);
  `), x2;
}
function S(e3) {
  function o2(o3) {
    return e3.draped ? t`coverage(vuv.${o3}, texelSize)` : t`sampleAA(vuv.${o3})`;
  }
  switch (e3.style) {
    case 3:
    case 0:
      return o2("y");
    case 4:
    case 1:
      return o2("x");
    case 5:
    case 2:
      return t`1.0 - (1.0 - ${o2("x")}) * (1.0 - ${o2("y")})`;
    default:
      return "0.0";
  }
}
var x = Object.freeze(Object.defineProperty({ __proto__: null, build: y }, Symbol.toStringTag, { value: "Module" }));

export {
  y,
  x
};
//# sourceMappingURL=chunk-HBX3TMAJ.js.map
