import {
  t as t2
} from "./chunk-JS3I6GIR.js";
import {
  r as r2
} from "./chunk-IFKJBQCK.js";
import {
  s as s3
} from "./chunk-TLTSPUO7.js";
import {
  A,
  _,
  h,
  n as n3
} from "./chunk-U55FA2EK.js";
import {
  Y
} from "./chunk-QNVJVDYZ.js";
import {
  i as i2
} from "./chunk-TFJXG32O.js";
import {
  n as n2
} from "./chunk-234CIOHE.js";
import {
  Z,
  tt,
  u as u2
} from "./chunk-V2H77UEV.js";
import {
  e4 as e
} from "./chunk-5EI5H4QX.js";
import {
  l2 as l,
  r2 as r,
  s as s2,
  u3 as u,
  w
} from "./chunk-GNMPGHLQ.js";
import {
  i3 as i,
  s2 as s
} from "./chunk-QY7XKUIV.js";
import {
  m,
  n2 as n,
  t2 as t
} from "./chunk-AL6YUTZM.js";

// node_modules/@arcgis/core/libs/basisu/BasisUTranscoder.js
function i3() {
  return t3 ??= (async () => {
    const i7 = await import("./basis_transcoder-NQFI7BQS.js"), t4 = await i7.default({ locateFile: (i8) => n2(`esri/libs/basisu/${i8}`) });
    return t4.initializeBasis(), t4;
  })(), t3;
}
var t3;

// node_modules/@arcgis/core/views/3d/webgl-engine/lib/BasisUtil.js
var r3 = null;
var i4 = null;
async function a() {
  return null == i4 && (i4 = i3(), r3 = await i4), i4;
}
function l2(e3, t4) {
  if (null == r3) return e3.byteLength;
  const n6 = new r3.BasisFile(new Uint8Array(e3)), s5 = u3(n6) ? o(n6.getNumLevels(0), n6.getHasAlpha(), n6.getImageWidth(0, 0), n6.getImageHeight(0, 0), t4) : 0;
  return n6.close(), n6.delete(), s5;
}
function g(e3, t4) {
  if (null == r3) return e3.byteLength;
  const n6 = new r3.KTX2File(new Uint8Array(e3)), s5 = c(n6) ? o(n6.getLevels(), n6.getHasAlpha(), n6.getWidth(), n6.getHeight(), t4) : 0;
  return n6.close(), n6.delete(), s5;
}
function o(e3, n6, r5, i7, a4) {
  const l4 = _(n6 ? Y.COMPRESSED_RGBA8_ETC2_EAC : Y.COMPRESSED_RGB8_ETC2), g3 = a4 && e3 > 1 ? (4 ** e3 - 1) / (3 * 4 ** (e3 - 1)) : 1;
  return Math.ceil(r5 * i7 * l4 * g3);
}
function u3(e3) {
  return e3.getNumImages() >= 1 && !e3.isUASTC();
}
function c(e3) {
  return e3.getFaces() >= 1 && e3.isETC1S();
}
async function m2(e3, t4, n6) {
  null == r3 && (r3 = await a());
  const s5 = new r3.BasisFile(new Uint8Array(n6));
  if (!u3(s5)) return null;
  s5.startTranscoding();
  const i7 = h2(e3, t4, s5.getNumLevels(0), s5.getHasAlpha(), s5.getImageWidth(0, 0), s5.getImageHeight(0, 0), (e4, t5) => s5.getImageTranscodedSizeInBytes(0, e4, t5), (e4, t5, n7) => s5.transcodeImage(n7, 0, e4, t5, 0, 0));
  return s5.close(), s5.delete(), i7;
}
async function T(e3, t4, n6) {
  null == r3 && (r3 = await a());
  const s5 = new r3.KTX2File(new Uint8Array(n6));
  if (!c(s5)) return null;
  s5.startTranscoding();
  const i7 = h2(e3, t4, s5.getLevels(), s5.getHasAlpha(), s5.getWidth(), s5.getHeight(), (e4, t5) => s5.getImageTranscodedSizeInBytes(e4, 0, 0, t5), (e4, t5, n7) => s5.transcodeImage(n7, e4, 0, 0, t5, 0, -1, -1));
  return s5.close(), s5.delete(), i7;
}
function h2(e3, s5, r5, i7, a4, l4, g3, o4) {
  const { compressedTextureETC: u5, compressedTextureS3TC: c3 } = e3.capabilities, [m4, T3] = u5 ? i7 ? [1, Y.COMPRESSED_RGBA8_ETC2_EAC] : [0, Y.COMPRESSED_RGB8_ETC2] : c3 ? i7 ? [3, Y.COMPRESSED_RGBA_S3TC_DXT5_EXT] : [2, Y.COMPRESSED_RGB_S3TC_DXT1_EXT] : [13, 6408], h5 = s5.hasMipmap ? r5 : Math.min(1, r5), d2 = [];
  for (let t4 = 0; t4 < h5; t4++) d2.push(new Uint8Array(g3(t4, m4))), o4(t4, m4, d2[t4]);
  return s5.internalFormat = T3, s5.hasMipmap = d2.length > 1, s5.samplingMode = s5.hasMipmap ? 9987 : 9729, s5.width = a4, s5.height = l4, new A(e3, s5, { type: "compressed", levels: d2 });
}

// node_modules/@arcgis/core/views/3d/webgl-engine/lib/DDSUtil.js
var n4 = () => i.getLogger("esri.views.3d.webgl-engine.lib.DDSUtil");
var o2 = 542327876;
var a2 = 131072;
var i5 = 4;
function s4(e3) {
  return e3.charCodeAt(0) + (e3.charCodeAt(1) << 8) + (e3.charCodeAt(2) << 16) + (e3.charCodeAt(3) << 24);
}
function l3(e3) {
  return String.fromCharCode(255 & e3, e3 >> 8 & 255, e3 >> 16 & 255, e3 >> 24 & 255);
}
var u4 = s4("DXT1");
var c2 = s4("DXT3");
var h3 = s4("DXT5");
var m3 = 31;
var f = 0;
var d = 1;
var p = 2;
var g2 = 3;
var D = 4;
var C = 7;
var w2 = 20;
var T2 = 21;
function S(e3, t4, n6) {
  const o4 = b(n6, t4.hasMipmap ?? false);
  if (null == o4) throw new Error("DDS texture data is null");
  const { textureData: a4, internalFormat: i7, width: s5, height: l4 } = o4;
  return t4.samplingMode = a4.levels.length > 1 ? 9987 : 9729, t4.hasMipmap = a4.levels.length > 1, t4.internalFormat = i7, t4.width = s5, t4.height = l4, new A(e3, t4, a4);
}
function b(e3, r5) {
  const s5 = new Int32Array(e3.buffer, e3.byteOffset, m3);
  if (s5[f] !== o2) return n4().error("Invalid magic number in DDS header"), null;
  if (!(s5[w2] & i5)) return n4().error("Unsupported format, must contain a FourCC code"), null;
  const S2 = s5[T2];
  let b2, _2;
  switch (S2) {
    case u4:
      b2 = 8, _2 = Y.COMPRESSED_RGB_S3TC_DXT1_EXT;
      break;
    case c2:
      b2 = 16, _2 = Y.COMPRESSED_RGBA_S3TC_DXT3_EXT;
      break;
    case h3:
      b2 = 16, _2 = Y.COMPRESSED_RGBA_S3TC_DXT5_EXT;
      break;
    default:
      return n4().error("Unsupported FourCC code:", l3(S2)), null;
  }
  let x = 1, E = s5[D], M2 = s5[g2];
  (3 & E || 3 & M2) && (n4().warn("Rounding up compressed texture size to nearest multiple of 4."), E = E + 3 & -4, M2 = M2 + 3 & -4);
  const X = E, A2 = M2;
  let R, v2;
  s5[p] & a2 && false !== r5 && (x = Math.max(1, s5[C]));
  let y = e3.byteOffset + s5[d] + 4;
  const F = [];
  for (let t4 = 0; t4 < x; ++t4) v2 = (E + 3 >> 2) * (M2 + 3 >> 2) * b2, R = new Uint8Array(e3.buffer, y, v2), F.push(R), y += v2, E = Math.max(1, E >> 1), M2 = Math.max(1, M2 >> 1);
  return { textureData: { type: "compressed", levels: F }, internalFormat: _2, width: X, height: A2 };
}

// node_modules/@arcgis/core/views/3d/webgl-engine/lib/textureUtils.js
var e2 = 16;
function n5(t4, n6) {
  return n6 = Math.floor(n6 / e2) * e2, Math.min(Math.round(t4 / e2) * e2, n6);
}
function r4(t4, n6) {
  return n6 = Math.floor(n6 / e2) * e2, Math.min(Math.ceil(t4 / e2) * e2, n6);
}
function o3(t4, e3) {
  const [n6, r5] = a3(t4, e3);
  return t4.width === n6 && t4.height === r5 ? t4 : i6(t4, n6, r5);
}
function a3({ width: t4, height: e3 }, { maxPreferredTexturePixels: r5, maxTextureSize: o4 }) {
  const a4 = Math.max(t4, e3), i7 = t4 * e3;
  if (a4 <= o4 && i7 <= r5) return [t4, e3];
  const h5 = Math.min(Math.sqrt(r5 / i7), o4 / a4);
  return [n5(Math.round(t4 * h5), o4), n5(Math.round(e3 * h5), o4)];
}
function i6(t4, e3, n6) {
  if (t4 instanceof ImageData) return i6(h4(t4), e3, n6);
  const r5 = document.createElement("canvas");
  r5.width = e3, r5.height = n6;
  return r5.getContext("2d").drawImage(t4, 0, 0, r5.width, r5.height), r5;
}
function h4(e3) {
  const n6 = document.createElement("canvas");
  n6.width = e3.width, n6.height = e3.height;
  const r5 = n6.getContext("2d");
  if (null == r5) throw new s("texture:context-failed", "Failed to create 2d context from HTMLCanvasElement");
  return r5.putImageData(e3, 0, 0), n6;
}

// node_modules/@arcgis/core/views/3d/webgl-engine/lib/Texture.js
var M = class {
  constructor(e3, r5) {
    this._data = e3, this.id = e(), this.events = new i2(), this._parameters = { ...j, ...r5 }, this._startPreload(e3);
  }
  dispose() {
    this.unload(), this._data = this.update = void 0;
  }
  _startPreload(e3) {
    e3 instanceof HTMLVideoElement ? (this.update = (t4) => this._update(e3, t4), this._startPreloadVideoElement(e3)) : e3 instanceof HTMLImageElement && this._startPreloadImageElement(e3);
  }
  _startPreloadVideoElement(e3) {
    if (!(Z(e3.src) || "auto" === e3.preload && e3.crossOrigin) && (e3.preload = "auto", e3.crossOrigin = "anonymous", e3.src = e3.src, e3.paused && e3.autoplay)) {
      const t4 = [];
      r2(e3, (e4) => t4.push(e4)).then(() => {
        e3.play();
      }).finally(() => t4.forEach((e4) => e4.remove()));
    }
  }
  _startPreloadImageElement(e3) {
    tt(e3.src) || Z(e3.src) || e3.crossOrigin || (e3.crossOrigin = "anonymous", e3.src = e3.src);
  }
  _createDescriptor(e3) {
    const t4 = new h();
    return t4.wrapMode = this._parameters.wrap ?? 10497, t4.flipped = !this._parameters.noUnpackFlip, t4.samplingMode = this._parameters.mipmap ? 9987 : 9729, t4.hasMipmap = !!this._parameters.mipmap, t4.preMultiplyAlpha = !!this._parameters.preMultiplyAlpha, t4.maxAnisotropy = this._parameters.maxAnisotropy ?? (this._parameters.mipmap ? e3.parameters.maxMaxAnisotropy : 1), t4.dataType = this._parameters.dataType ?? t4.dataType, t4.pixelFormat = this._parameters.pixelFormat ?? t4.pixelFormat, t4.internalFormat = this._parameters.internalFormat ?? t4.internalFormat, t4;
  }
  get glTexture() {
    return this._glTexture ?? this._emptyTexture;
  }
  get loaded() {
    return null != this._glTexture;
  }
  get usedMemory() {
    return this._glTexture?.usedMemory || v(this._data, this._parameters);
  }
  load(e3) {
    if (this._loadingPromise) return this._loadingPromise;
    if (this._glTexture) return this._glTexture;
    const t4 = this._data;
    return null == t4 ? (this._glTexture = new A(e3, this._createDescriptor(e3), null), this._glTexture) : (this._emptyTexture = e3.emptyTexture, this._parameters.reloadable || (this._data = void 0), "string" == typeof t4 ? this._loadFromURL(e3, t4) : t4 instanceof Image ? this._loadFromImageElement(e3, t4) : t4 instanceof HTMLVideoElement ? this._loadFromVideoElement(e3, t4) : t4 instanceof ImageData || t4 instanceof HTMLCanvasElement ? this._loadFromImage(e3, t4) : t(t4) && "image/vnd-ms.dds" === this._parameters.encoding ? this._loadFromDDSData(e3, t4) : n(t4) && "image/vnd-ms.dds" === this._parameters.encoding ? this._loadFromDDSData(e3, new Uint8Array(t4)) : (n(t4) || t(t4)) && "image/ktx2" === this._parameters.encoding ? this._loadFromKTX2(e3, t4) : (n(t4) || t(t4)) && "image/x.basis" === this._parameters.encoding ? this._loadFromBasis(e3, t4) : n(t4) ? this._loadFromPixelData(e3, new Uint8Array(t4)) : m(t4) ? this._loadFromPixelData(e3, t4) : null);
  }
  _update(e3, t4) {
    return null == this._glTexture || e3.readyState < HTMLMediaElement.HAVE_CURRENT_DATA || t4 === e3.currentTime ? t4 : (this._glTexture.setData(e3), this._glTexture.descriptor.hasMipmap && this._glTexture.generateMipmap(), this._parameters.updateCallback && this._parameters.updateCallback(), e3.currentTime);
  }
  _loadFromDDSData(e3, t4) {
    return this._glTexture = S(e3, this._createDescriptor(e3), t4), this._emptyTexture = null, this._glTexture;
  }
  _loadFromKTX2(e3, t4) {
    return this._loadAsync(() => T(e3, this._createDescriptor(e3), t4).then((e4) => (this._glTexture = e4, e4)));
  }
  _loadFromBasis(e3, t4) {
    return this._loadAsync(() => m2(e3, this._createDescriptor(e3), t4).then((e4) => (this._glTexture = e4, e4)));
  }
  _loadFromPixelData(e3, t4) {
    s3(this._parameters.width > 0 && this._parameters.height > 0);
    const r5 = this._createDescriptor(e3);
    return 6407 !== r5.pixelFormat && 6408 !== r5.pixelFormat || (r5.compress = this._parameters.compressionOptions), r5.width = this._parameters.width ?? 0, r5.height = this._parameters.height ?? 0, this._glTexture = new A(e3, r5, t4), this._glTexture;
  }
  _loadFromURL(e3, t4) {
    return this._loadAsync(async (r5) => {
      const i7 = await t2(t4, { signal: r5 });
      return s2(r5), this._loadFromImage(e3, i7);
    });
  }
  _loadFromImageElement(e3, t4) {
    return t4.complete ? this._loadFromImage(e3, t4) : this._loadAsync(async (r5) => {
      const i7 = await u2(t4, t4.src, false, r5);
      return s2(r5), this._loadFromImage(e3, i7);
    });
  }
  _loadFromVideoElement(e3, t4) {
    return t4.readyState >= HTMLMediaElement.HAVE_CURRENT_DATA ? this._loadFromImage(e3, t4) : this._loadFromVideoElementAsync(e3, t4);
  }
  _loadFromVideoElementAsync(t4, r5) {
    return this._loadAsync((a4) => new Promise((n6, l4) => {
      const m4 = () => {
        r5.removeEventListener("loadeddata", h5), r5.removeEventListener("error", p2), l(d2);
      }, h5 = () => {
        r5.readyState >= HTMLMediaElement.HAVE_CURRENT_DATA && (m4(), n6(this._loadFromImage(t4, r5)));
      }, p2 = (t5) => {
        m4(), l4(t5 || new s("texture:load-error", "Failed to load video"));
      };
      r5.addEventListener("loadeddata", h5), r5.addEventListener("error", p2);
      const d2 = w(a4, () => p2(u()));
    }));
  }
  _loadFromImage(e3, t4) {
    let r5 = t4;
    r5 instanceof HTMLVideoElement || (r5 = o3(r5, e3.parameters));
    const i7 = U(r5);
    this._parameters.width = i7.width, this._parameters.height = i7.height;
    const a4 = this._createDescriptor(e3);
    return a4.width = i7.width, a4.height = i7.height, a4.compress = this._parameters.compressionOptions, this._glTexture = new A(e3, a4, r5), this._emptyTexture = null, this.events.emit("loaded"), this._glTexture;
  }
  _loadAsync(e3) {
    const t4 = new AbortController();
    this._loadingController = t4;
    const r5 = e3(t4.signal);
    this._loadingPromise = r5;
    const i7 = () => {
      this._loadingController === t4 && (this._loadingController = null), this._loadingPromise === r5 && (this._loadingPromise = null), this._emptyTexture = null;
    };
    return r5.then(i7, i7), r5;
  }
  unload() {
    if (this._glTexture = r(this._glTexture), this._emptyTexture = null, null != this._loadingController) {
      const e3 = this._loadingController;
      this._loadingController = null, this._loadingPromise = null, e3.abort();
    }
    this.events.emit("unloaded");
  }
  get parameters() {
    return this._parameters;
  }
};
function v(e3, t4) {
  if (null == e3) return 0;
  if (n(e3) || t(e3)) return "image/ktx2" === t4.encoding ? g(e3, !!t4.mipmap) : "image/x.basis" === t4.encoding ? l2(e3, !!t4.mipmap) : e3.byteLength;
  const { width: r5, height: i7 } = e3 instanceof Image || e3 instanceof ImageData || e3 instanceof HTMLCanvasElement || e3 instanceof HTMLVideoElement ? U(e3) : t4, a4 = t4.pixelFormat ?? 6408, s5 = n3(a4);
  return (t4.mipmap ? 4 / 3 : 1) * r5 * i7 * s5 || 0;
}
function U(e3) {
  return e3 instanceof HTMLVideoElement ? { width: e3.videoWidth, height: e3.videoHeight } : e3;
}
var j = { wrap: { s: 10497, t: 10497 }, mipmap: true, noUnpackFlip: false, preMultiplyAlpha: false };

export {
  n5 as n,
  r4 as r,
  M
};
//# sourceMappingURL=chunk-UR6CZJPX.js.map
