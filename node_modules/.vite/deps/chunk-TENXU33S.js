import {
  a,
  d as d2,
  e as e6,
  f as f2,
  i as i2,
  i2 as i3,
  s as s2
} from "./chunk-BLCKE43G.js";
import {
  n as n2
} from "./chunk-CHC4AAHW.js";
import {
  i
} from "./chunk-CT7HOWYG.js";
import {
  d,
  e as e5
} from "./chunk-BZBDEPRV.js";
import {
  p
} from "./chunk-MXP2VO3L.js";
import {
  f,
  p as p2,
  w
} from "./chunk-OWSUTT7E.js";
import {
  t as t2
} from "./chunk-WNQORCSA.js";
import {
  e as e2
} from "./chunk-COMSADUT.js";
import {
  e as e4
} from "./chunk-3PAAA3FK.js";
import {
  r
} from "./chunk-EGPAQBOO.js";
import {
  e
} from "./chunk-6GHQTYW5.js";
import {
  s
} from "./chunk-WJ3E33GQ.js";
import {
  e as e3
} from "./chunk-SZTZNZQW.js";
import {
  n,
  t
} from "./chunk-CFXCM2NO.js";

// node_modules/@arcgis/core/chunks/LineMarker.glsl.js
function b(b2) {
  const j2 = new s(), { space: L, anchor: D, hasTip: k, hasScreenSizePerspective: M } = b2, C = 2 === L, $ = 1 === L;
  j2.include(f2, b2), j2.include(i3, b2), j2.include(i, b2);
  const { vertex: W, fragment: U, varyings: O } = j2;
  f(W, b2), j2.attributes.add("position", "vec3"), j2.attributes.add("previousDelta", "vec4"), j2.attributes.add("uv0", "vec2"), O.add("vColor", "vec4"), O.add("vpos", "vec3", { invariant: true }), O.add("vUV", "vec2"), O.add("vSize", "float"), k && O.add("vLineWidth", "float"), W.uniforms.add(new e("nearFar", ({ camera: e7 }) => e7.nearFar), new e4("viewport", ({ camera: e7 }) => e7.fullViewport)).code.add(t`vec4 projectAndScale(vec4 pos) {
vec4 posNdc = proj * pos;
posNdc.xy *= viewport.zw / posNdc.w;
return posNdc;
}`), W.code.add(t`void clip(vec4 pos, inout vec4 prev) {
float vnp = nearFar[0] * 0.99;
if (prev.z > -nearFar[0]) {
float interpolation = (-vnp - pos.z) / (prev.z - pos.z);
prev = mix(pos, prev, interpolation);
}
}`), C ? (j2.attributes.add("normal", "vec3"), p2(W), W.constants.add("tiltThreshold", "float", 0.7), W.code.add(t`vec3 perpendicular(vec3 v) {
vec3 n = (viewNormal * vec4(normal.xyz, 1.0)).xyz;
vec3 n2 = cross(v, n);
vec3 forward = vec3(0.0, 0.0, 1.0);
float tiltDot = dot(forward, n);
return abs(tiltDot) < tiltThreshold ? n : n2;
}`)) : W.code.add(t`vec2 perpendicular(vec2 v) {
return vec2(v.y, -v.x);
}`);
  const T = C ? "vec3" : "vec2";
  return W.code.add(t`
      ${T} normalizedSegment(${T} pos, ${T} prev) {
        ${T} segment = pos - prev;
        float segmentLen = length(segment);

        // normalize or zero if too short
        return (segmentLen > 0.001) ? segment / segmentLen : ${C ? "vec3(0.0, 0.0, 0.0)" : "vec2(0.0, 0.0)"};
      }

      ${T} displace(${T} pos, ${T} prev, float displacementLen) {
        ${T} segment = normalizedSegment(pos, prev);

        ${T} displacementDirU = perpendicular(segment);
        ${T} displacementDirV = segment;

        ${1 === D ? "pos -= 0.5 * displacementLen * displacementDirV;" : ""}

        return pos + displacementLen * (uv0.x * displacementDirU + uv0.y * displacementDirV);
      }
    `), $ && (W.uniforms.add(new t2("inverseProjectionMatrix", ({ camera: e7 }) => e7.inverseProjectionMatrix)), W.code.add(t`vec3 inverseProject(vec4 posScreen) {
posScreen.xy = (posScreen.xy / viewport.zw) * posScreen.w;
return (inverseProjectionMatrix * posScreen).xyz;
}`), W.code.add(t`bool rayIntersectPlane(vec3 rayDir, vec3 planeOrigin, vec3 planeNormal, out vec3 intersection) {
float cos = dot(rayDir, planeNormal);
float t = dot(planeOrigin, planeNormal) / cos;
intersection = t * rayDir;
return abs(cos) > 0.001 && t > 0.0;
}`), W.uniforms.add(new r("perScreenPixelRatio", ({ camera: e7 }) => e7.perScreenPixelRatio)), W.code.add(t`
      vec4 toFront(vec4 displacedPosScreen, vec3 posLeft, vec3 posRight, vec3 prev, float lineWidth) {
        // Project displaced position back to camera space
        vec3 displacedPos = inverseProject(displacedPosScreen);

        // Calculate the plane that we want the marker to lie in. Note that this will always be an approximation since ribbon lines are generally
        // not planar and we do not know the actual position of the displaced prev vertices (they are offset in screen space, too).
        vec3 planeNormal = normalize(cross(posLeft - posRight, posLeft - prev));
        vec3 planeOrigin = posLeft;

        ${n(b2.hasCap, "if(prev.z > posLeft.z) {\n                vec2 diff = posLeft.xy - posRight.xy;\n                planeOrigin.xy += perpendicular(diff) / 2.0;\n             }")};

        // Move the plane towards the camera by a margin dependent on the line width (approximated in world space). This tolerance corrects for the
        // non-planarity in most cases, but sharp joins can place the prev vertices at arbitrary positions so markers can still clip.
        float offset = lineWidth * perScreenPixelRatio;
        planeOrigin *= (1.0 - offset);

        // Intersect camera ray with the plane and make sure it is within clip space
        vec3 rayDir = normalize(displacedPos);
        vec3 intersection;
        if (rayIntersectPlane(rayDir, planeOrigin, planeNormal, intersection) && intersection.z < -nearFar[0] && intersection.z > -nearFar[1]) {
          return vec4(intersection.xyz, 1.0);
        }

        // Fallback: use depth of pos or prev, whichever is closer to the camera
        float minDepth = planeOrigin.z > prev.z ? length(planeOrigin) : length(prev);
        displacedPos *= minDepth / length(displacedPos);
        return vec4(displacedPos.xyz, 1.0);
      }
  `)), w(W), j2.include(e6), W.main.add(t`
    // Check for special value of uv0.y which is used by the Renderer when graphics
    // are removed before the VBO is recompacted. If this is the case, then we just
    // project outside of clip space.
    if (uv0.y == 0.0) {
      // Project out of clip space
      gl_Position = vec4(1e038, 1e038, 1e038, 1.0);
    }
    else {
      vec4 pos  = view * vec4(position, 1.0);
      vec4 prev = view * vec4(position + previousDelta.xyz * previousDelta.w, 1.0);

      float lineWidth = getLineWidth(${n(M, "pos.xyz")});
      float screenMarkerSize = getScreenMarkerSize(lineWidth);

      clip(pos, prev);

      ${C ? t`${n(b2.hideOnShortSegments, t`
                if (areWorldMarkersHidden(pos.xyz, prev.xyz)) {
                  // Project out of clip space
                  gl_Position = vec4(1e038, 1e038, 1e038, 1.0);
                  return;
                }`)}
            pos.xyz = displace(pos.xyz, prev.xyz, getWorldMarkerSize(pos.xyz));
            vec4 displacedPosScreen = projectAndScale(pos);` : t`
            vec4 posScreen = projectAndScale(pos);
            vec4 prevScreen = projectAndScale(prev);
            vec4 displacedPosScreen = posScreen;

            displacedPosScreen.xy = displace(posScreen.xy, prevScreen.xy, screenMarkerSize);
            ${n($, t`
                vec2 displacementDirU = perpendicular(normalizedSegment(posScreen.xy, prevScreen.xy));

                // We need three points of the ribbon line in camera space to calculate the plane it lies in
                // Note that we approximate the third point, since we have no information about the join around prev
                vec3 lineRight = inverseProject(posScreen + lineWidth * vec4(displacementDirU.xy, 0.0, 0.0));
                vec3 lineLeft = pos.xyz + (pos.xyz - lineRight);

                pos = toFront(displacedPosScreen, lineLeft, lineRight, prev.xyz, lineWidth);
                displacedPosScreen = projectAndScale(pos);`)}`}
      forwardViewPosDepth(pos.xyz);
      // Convert back into NDC
      displacedPosScreen.xy = (displacedPosScreen.xy / viewport.zw) * displacedPosScreen.w;

      // Convert texture coordinate into [0,1]
      vUV = (uv0 + 1.0) / 2.0;
      ${n(!C, "vUV = noPerspectiveWrite(vUV, displacedPosScreen.w);")}
      ${n(k, "vLineWidth = noPerspectiveWrite(lineWidth, displacedPosScreen.w);")}

      vSize = screenMarkerSize;
      vColor = getColor();

      // Use camera space for slicing
      vpos = pos.xyz;

      gl_Position = displacedPosScreen;
    }`), U.include(p, b2), j2.include(n2, b2), U.include(e5), U.uniforms.add(new e2("intrinsicColor", ({ color: e7 }) => e7), new e3("tex", ({ markerTexture: e7 }) => e7)).constants.add("texelSize", "float", 1 / i2).code.add(t`float markerAlpha(vec2 samplePos) {
samplePos += vec2(0.5, -0.5) * texelSize;
float sdf = texture(tex, samplePos).r;
float pixelDistance = sdf * vSize;
pixelDistance -= 0.5;
return clamp(0.5 - pixelDistance, 0.0, 1.0);
}`), k && (j2.include(d2), U.constants.add("relativeMarkerSize", "float", s2 / i2).constants.add("relativeTipLineWidth", "float", a).code.add(t`
    float tipAlpha(vec2 samplePos) {
      // Convert coordinates s.t. they are in pixels and relative to the tip of an arrow marker
      samplePos -= vec2(0.5, 0.5 + 0.5 * relativeMarkerSize);
      samplePos *= vSize;

      float halfMarkerSize = 0.5 * relativeMarkerSize * vSize;
      float halfTipLineWidth = 0.5 * max(1.0, relativeTipLineWidth * noPerspectiveRead(vLineWidth));

      ${n(C, "halfTipLineWidth *= fwidth(samplePos.y);")}

      float distance = max(abs(samplePos.x) - halfMarkerSize, abs(samplePos.y) - halfTipLineWidth);
      return clamp(0.5 - distance, 0.0, 1.0);
    }
  `)), j2.include(d, b2), j2.include(d2), U.main.add(t`
    discardBySlice(vpos);
    discardByTerrainDepth();

    vec4 finalColor = intrinsicColor * vColor;

    // Cancel out perspective correct interpolation if in screen space or draped
    vec2 samplePos = ${n(!C, "noPerspectiveRead(vUV)", "vUV")};
    finalColor.a *= ${k ? "max(markerAlpha(samplePos), tipAlpha(samplePos))" : "markerAlpha(samplePos)"};
    outputColorHighlightOID(finalColor, vpos, finalColor.rgb);`), j2;
}
var j = Object.freeze(Object.defineProperty({ __proto__: null, build: b }, Symbol.toStringTag, { value: "Module" }));

export {
  b,
  j
};
//# sourceMappingURL=chunk-TENXU33S.js.map
