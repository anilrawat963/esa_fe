import {
  d,
  l,
  n as n3
} from "./chunk-P355ISZZ.js";
import {
  i
} from "./chunk-CW4AXF3Q.js";
import {
  m
} from "./chunk-MXP2VO3L.js";
import {
  e as e2
} from "./chunk-COMSADUT.js";
import {
  e as e3
} from "./chunk-U5J3MCMX.js";
import {
  e as e4
} from "./chunk-SZ5DGQ75.js";
import {
  e as e5
} from "./chunk-3PAAA3FK.js";
import {
  a as a2
} from "./chunk-W6L6ZQPE.js";
import {
  e
} from "./chunk-6GHQTYW5.js";
import {
  s
} from "./chunk-WJ3E33GQ.js";
import {
  r
} from "./chunk-YOYO2XMY.js";
import {
  n as n2,
  t
} from "./chunk-CFXCM2NO.js";
import {
  a
} from "./chunk-ZVTEFYZX.js";
import {
  n
} from "./chunk-WDTGOP77.js";
import {
  o
} from "./chunk-AZXJIEZ6.js";

// node_modules/@arcgis/core/views/3d/webgl-engine/core/shaderLibrary/shading/MultipassGeometryTest.glsl.js
function r2(r3) {
  r3.include(a2), r3.uniforms.add(new e3("geometryDepthTexture", (e6) => e6.geometryDepth?.attachment)), r3.code.add(t`bool geometryDepthTest(vec2 pos, float elementDepth) {
float geometryDepth = linearDepthFromTexture(geometryDepthTexture, pos);
return (elementDepth < (geometryDepth - 1.0));
}`);
}

// node_modules/@arcgis/core/chunks/LineCallout.glsl.js
function h(i2) {
  const h2 = new s(), { vertex: u2, fragment: b } = h2, { terrainDepthTest: z } = i2;
  return u2.include(l), h2.include(d, i2), h2.vertex.include(m, i2), h2.attributes.add("uv0", "vec2"), u2.uniforms.add(new e5("viewport", (e6) => e6.camera.fullViewport), new r("lineSize", (e6, i3) => e6.size > 0 ? Math.max(1, e6.size) * i3.camera.pixelRatio : 0), new e("pixelToNDC", (i3) => o(w, 2 / i3.camera.fullViewport[2], 2 / i3.camera.fullViewport[3])), new r("borderSize", (e6, i3) => e6.borderColor ? i3.camera.pixelRatio : 0), new e4("screenOffset", (i3, r3) => o(w, i3.horizontalScreenOffset * r3.camera.pixelRatio, 0))), h2.varyings.add("coverageSampling", "vec4"), h2.varyings.add("lineSizes", "vec2"), z && h2.varyings.add("depth", "float"), i2.occlusionTestEnabled && h2.include(n3), i2.hasScreenSizePerspective && i(u2), u2.main.add(t`
    ProjectHUDAux projectAux;
    vec4 endPoint = projectPositionHUD(projectAux);

    vec3 vpos = projectAux.posModel;
    if (rejectBySlice(vpos)) {
      gl_Position = vec4(1e38, 1e38, 1e38, 1.0);
      return;
    }
    ${n2(i2.occlusionTestEnabled, t`if (!testHUDVisibility(endPoint)) {
             gl_Position = vec4(1e38, 1e38, 1e38, 1.0);
             return;
           }`)}

    ${i2.hasScreenSizePerspective ? t`vec3 perspectiveFactor = screenSizePerspectiveScaleFactor(projectAux.absCosAngle, projectAux.distanceToCamera, screenSizePerspectiveAlignment);
               vec2 screenOffsetScaled = applyScreenSizePerspectiveScaleFactorVec2(screenOffset, perspectiveFactor);` : "vec2 screenOffsetScaled = screenOffset;"}
    // Add view dependent polygon offset to get exact same original starting point. This is mostly used to get the
    // correct depth value
    vec3 posView = (view * vec4(position, 1.0)).xyz;
    ${n2(z, "depth = posView.z;")}

    applyHUDViewDependentPolygonOffset(centerOffsetAndDistance.w, projectAux.absCosAngle, posView);
    vec4 startPoint = proj * vec4(posView, 1.0);

    // Apply screen offset to both start and end point
    vec2 screenOffsetNorm = screenOffsetScaled * 2.0 / viewport.zw;
    startPoint.xy += screenOffsetNorm * startPoint.w;
    endPoint.xy += screenOffsetNorm * endPoint.w;

    // Align start and end to pixel origin
    vec4 startAligned = alignToPixelOrigin(startPoint, viewport.zw);
    vec4 endAligned = alignToPixelOrigin(endPoint, viewport.zw);
    ${n2(i2.hudDepth, i2.hudDepthAlignStart ? "endAligned = vec4(endAligned.xy / endAligned.w * startAligned.w, startAligned.zw);" : "startAligned = vec4(startAligned.xy / startAligned.w * endAligned.w, endAligned.zw);")}
    vec4 projectedPosition = mix(startAligned, endAligned, uv0.y);

    // The direction of the line in screen space
    vec2 screenSpaceDirection = normalize(endAligned.xy / endAligned.w - startAligned.xy / startAligned.w);
    vec2 perpendicularScreenSpaceDirection = vec2(screenSpaceDirection.y, -screenSpaceDirection.x);
    ${i2.hasScreenSizePerspective ? t`float lineSizeScaled = applyScreenSizePerspectiveScaleFactorFloat(lineSize, perspectiveFactor);
               float borderSizeScaled = applyScreenSizePerspectiveScaleFactorFloat(borderSize, perspectiveFactor);` : t`float lineSizeScaled = lineSize;
               float borderSizeScaled = borderSize;`}
    float halfPixelSize = lineSizeScaled * 0.5;

    // Compute full ndc offset, adding 1px padding for doing anti-aliasing and the border size
    float padding = 1.0 + borderSizeScaled;
    vec2 ndcOffset = (-halfPixelSize - padding + uv0.x * (lineSizeScaled + padding + padding)) * pixelToNDC;

    // Offset x/y from the center of the line in screen space
    projectedPosition.xy += perpendicularScreenSpaceDirection * ndcOffset * projectedPosition.w;

    // Compute a coverage varying which we can use in the fragment shader to determine
    // how much a pixel is actually covered by the line (i.e. to anti alias the line).
    // This works by computing two coordinates that can be linearly interpolated and then
    // subtracted to find out how far away from the line edge we are.
    float edgeDirection = (uv0.x * 2.0 - 1.0);

    float halfBorderSize = 0.5 * borderSizeScaled;
    float halfPixelSizeAndBorder = halfPixelSize + halfBorderSize;
    float outerEdgeCoverageSampler = edgeDirection * (halfPixelSizeAndBorder + halfBorderSize + 1.0);

    float isOneSided = float(lineSizeScaled < 2.0 && borderSize < 2.0);

    coverageSampling = vec4(
      // Edge coordinate
      outerEdgeCoverageSampler,

      // Border edge coordinate
      outerEdgeCoverageSampler - halfPixelSizeAndBorder * isOneSided,

      // Line offset
      halfPixelSize - 0.5,

      // Border offset
      halfBorderSize - 0.5 + halfPixelSizeAndBorder * (1.0 - isOneSided)
    );

    lineSizes = vec2(lineSizeScaled, borderSizeScaled);
    gl_Position = projectedPosition;`), b.uniforms.add(new e2("uColor", (e6) => e6.color ?? a), new e2("borderColor", (e6) => e6.borderColor ?? a)), z && (b.include(r2, i2), b.uniforms.add(new e("inverseViewport", (e6) => e6.inverseViewport))), b.main.add(t`
    ${n2(z, "if( geometryDepthTest(gl_FragCoord.xy * inverseViewport, depth) ){ discard; }")}

    vec2 coverage = min(1.0 - clamp(abs(coverageSampling.xy) - coverageSampling.zw, 0.0, 1.0), lineSizes);

    float borderAlpha = uColor.a * borderColor.a * coverage.y;
    float colorAlpha = uColor.a * coverage.x;

    float finalAlpha = mix(borderAlpha, 1.0, colorAlpha);
    ${n2(!i2.hudDepth, t`vec3 finalRgb = mix(borderColor.rgb * borderAlpha, uColor.rgb, colorAlpha);
           fragColor = vec4(finalRgb, finalAlpha);`)}`), h2;
}
var w = n();
var u = Object.freeze(Object.defineProperty({ __proto__: null, build: h }, Symbol.toStringTag, { value: "Module" }));

export {
  h,
  u
};
//# sourceMappingURL=chunk-PU7CAQGZ.js.map
